{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"top\"></a>\n",
    "# QKeras-Mod Explained\n",
    "Author: Luca Urbinati, Date: 18/01/2024, v.1.0, Email: luca.urbinati@polito.it\n",
    "***\n",
    "\n",
    "### Content of this notebook\n",
    "[Chapter 1](#ch1): how to design a quantized model (with and without fused batch normalization) using a modified version of QKeras [1] that quantizes weights <b>and activations</b> to integers starting from a Keras model;\n",
    "\n",
    "[Chapter 2](#ch2): <b>compare inference results</b> between the Keras model and the quantized one;\n",
    "\n",
    "[Chapter 3](#ch3): how to <b>extract quantization factors</b> (scaling factors and zero points) from each layer of the QKeras model to match the uniform quantization theory of Tensorflow Lite [2][3];\n",
    "\n",
    "[Chapter 4](#ch4): how to use <b>AutoQKeras</b> to search for the best mixed-precision quantized model.\n",
    "\n",
    "### Requirements before to start\n",
    "- Read [this QKeras tutorial](https://github.com/google/qkeras/blob/master/notebook/QKerasTutorial.ipynb) to become confident with QKeras.\n",
    "- Install the conda environment [qkeras-env.yml](https://github.com/LucaUrbinati44/qkeras-mod/blob/main/qkeras-env.yml) provided in this repo and activate it (_conda activate qkeras-env_).\n",
    "- Apply the patch to QKeras' installation to have access to the modified version of QKeras (see the [README](https://github.com/LucaUrbinati44/qkeras-mod/blob/main/README.md)). \n",
    "\n",
    "### Main features of QKeras:\n",
    "- quantization-aware training\n",
    "- per-channel quantization for weights (not for activations [4])\n",
    "- by default weights quantization; if properly used, activations quantization too\n",
    "- it uses affine quantization mapping formula, uniform quantization and 2*max(abs(tensor)) as floating-point range instead of the most common max-min\n",
    "\n",
    "### Publications using this code\n",
    "- Luca Urbinati and Mario R. Casu, \"High-Level Design of Precision-Scalable DNN Accelerators Based on Sum-Together Multiplier\", in the review process.\n",
    "\n",
    "### References\n",
    "[1] QKeras: https://github.com/google/qkeras\n",
    "\n",
    "[2] B. Jacob et al., \"Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference,\" arXiv:1712.05877 [cs, stat], Dec. 2017. Available: http://arxiv.org/abs/1712.05877\n",
    "\n",
    "[3] Mao, Lei. \"Quantization for Neural Networks\". Lei Mao’s Log Book, May 17, 2020, https://leimao.github.io/article/Neural-Networks-Quantization/\n",
    "\n",
    "[4] M. Nagel, M. Fournarakis, R. A. Amjad, Y. Bondarenko, M. van Baalen, and T. Blankevoort, “A White Paper on Neural Network Quantization.” arXiv, Jun. 15, 2021. Available: http://arxiv.org/abs/2106.08295\n",
    "\n",
    "[5] H. Wu, P. Judd, X. Zhang, M. Isaev, and P. Micikevicius, “Integer Quantization for Deep Learning Inference: Principles and Empirical Evaluation,” arXiv:2004.09602 [cs, stat], Apr. 2020, Accessed: Dec. 22, 2021. [Online]. Available: http://arxiv.org/abs/2004.09602."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a class=\"anchor\" id=\"ch0\"></a>\n",
    "# 0) Import libraries and data\n",
    "\n",
    "Go to next: [Ch. 1](#ch1).\n",
    "\n",
    "Go to others: [Ch. 0](#ch0), [Ch. 1](#ch1), [Ch. 2](#ch2), [Ch. 3](#ch3), [Ch. 4](#ch4).\n",
    "\n",
    "Go to [Top](#top)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from IPython.utils import io\n",
    "import math\n",
    "from copy import deepcopy as dc\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from qkeras import *\n",
    "from qkeras.utils import *\n",
    "\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "tf.keras.backend.floatx()\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize, precision=128, suppress=True)\n",
    "\n",
    "if tf.config.list_physical_devices('GPU') == []:\n",
    "    print(\"No GPU available\")\n",
    "else:\n",
    "    print(\"GPU available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 0\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed: int = 42) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    tf.experimental.numpy.random.seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    print(f\"Random seed set as {seed}\")\n",
    "\n",
    "set_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "def get_data():\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train = x_train.reshape(x_train.shape + (1,)).astype(\"float32\")\n",
    "    x_test = x_test.reshape(x_test.shape + (1,)).astype(\"float32\")\n",
    "\n",
    "    x_train /= 256.0\n",
    "    x_test /= 256.0\n",
    "\n",
    "    x_mean = np.mean(x_train, axis=0)\n",
    "\n",
    "    x_train -= x_mean\n",
    "    x_test -= x_mean\n",
    "\n",
    "    nb_classes = np.max(y_train)+1\n",
    "    y_train = to_categorical(y_train, nb_classes)\n",
    "    y_test = to_categorical(y_test, nb_classes)\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "input_width = 28\n",
    "input_channels = 1\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = get_data()\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a class=\"anchor\" id=\"ch1\"></a>\n",
    "# 1) Quantized network design\n",
    "\n",
    "Go to next: [Ch. 2](#ch2).\n",
    "\n",
    "Go to others: [Ch. 0](#ch0), [Ch. 1](#ch1), [Ch. 2](#ch2), [Ch. 3](#ch3), [Ch. 4](#ch4).\n",
    "\n",
    "Go to [Top](#top).\n",
    "\n",
    "The goal of this chapter is to design a Convolutional network that provides quantized inputs and weights to its 2D-Conv kernels, as an example.\n",
    "\n",
    "It is important to know that inside the quantized kernels of QKeras (```QConv2D```, ```QDepthwiseConv2D```, ```QDense```) there are the corresponding TensorFlow kernels (```tf.keras.backend.conv2d()```, ```tf.keras.backend.depthwise_conv2d()```, ```tf.keras.backend.dot()```) which are floating-point kernels. \n",
    "\n",
    "When running one of these quantized kernels, QKeras partially uses the technique called [\"fake quantization\"](https://github.com/google/qkeras/issues/96#issuecomment-1210877800) that is the same technique used by Tensorflow Lite [2]. This technique consists in quantizing and dequantizing inputs and weights before running the floating-point kernel. In this way, inputs, weights (and then outputs) remain floating point numbers, but can represent quantized values only. However, there is a difference: QKeras does not fake-quantize the inputs, i.e. they remain \"true\" floating point numbers so they can represent any number in the floating point range (you can look at the source code of ```QConv2D()``` in [qconvolutional.py#L294](https://github.com/google/qkeras/blob/eb6e0dc86c43128c6708988d9cb54d1e106685a4/qkeras/qconvolutional.py#L294) yourself). The same holds also for the outputs: they remain in floating point because computing a kernel with floating-point inputs and fake-quantized weights gives floating-point outputs.\n",
    "\n",
    "To tackle this problem, we perform a ```quantized_bits()``` operation on the input feature map tensor, by inserting a ```QActivation``` layer. ```quantized_bits()``` performs a quantization-dequantization (q-deq) operation on the floating point tensor. Thanks to this ```QActivation``` layer, we can extract the quantization parameters of the input feature map tensor and quantize it to integer values (see [Chapter 2](#ch2)). Now the output tensor of ```QConv2D``` is fake-quantized completely because both inputs and weights to this layer are fake-quantized.\n",
    "\n",
    "The next two layers are a standard ```ReLU``` followed by another ```QActivation``` with ```quantized_bits()```. We could have used ```QActivation(\"quantized_relu(bits,integer)\")```, but ```quantized_relu()``` does not quantize the input data in the same way as ```quantized_bits()```. In particular, the argument ```alpha=\"auto\"``` is not present in ```quantized_relu()```, so it does not quantize with the standard affine quantization mapping formula [2][3] (shown below) which is the quantization we want to implement.\n",
    "$$x_q = \\text{clip}\\Big( \\text{round}\\big(\\frac{1}{s} x + z\\big), \\alpha_q, \\beta_q \\Big)$$\n",
    "Thus, in order to tell QKeras to use this quantization mapping formula, we have to set ```alpha=\"auto\"``` in ```quantized_bits()``` for all QKeras layers.\n",
    "\n",
    "The only drawback of using ```quantized_bits()``` is that it implements only a symmetric quantized range when ```alpha=\"auto\"``` (as written in the comment [quantizers.py#L1404](https://github.com/google/qkeras/blob/c5051b51ac5d8db7b5d235419a1538258a35a8a7/qkeras/quantizers.py#L1404)), so even if we set ```symmetric=0``` and ```keep_negative=0```, it automatically forces ```symmetric=1``` ([quantizers.py#L524](https://github.com/google/qkeras/blob/b91d8815b31f05ddf9c7b6d62381df9be72a570a/qkeras/quantizers.py#L524)) and ```keep_negative=1``` ([quantizers.py#L584](https://github.com/google/qkeras/blob/b91d8815b31f05ddf9c7b6d62381df9be72a570a/qkeras/quantizers.py#L524), [quantizers.py#L603](https://github.com/google/qkeras/blob/b91d8815b31f05ddf9c7b6d62381df9be72a570a/qkeras/quantizers.py#L524)). Thefore, as an example, ```quantized_bits(4,4,0,0,alpha='auto')``` will be treated by QKeras as ```quantized_bits(4,4,1,1,alpha='auto')```. \n",
    "This implies that our features will lose 1 bit in the positive range after passing a ReLU activation.\n",
    "\n",
    "Finally, the ```QActivation``` layer that follows the ```ReLU``` can be used to fake-quantize the features to another bitwidth precision. ```ReLU``` can NOT be passed to ```QConv2D``` in the ```activation``` argument because it would be threated as ```quantized_relu()```.\n",
    "\n",
    "Regarding the number of bits for ```quantized_bits()```, we want that ```bits``` = ```integer``` because our target is to implement integer-only arithmetic. \n",
    "\n",
    "<br><br>\n",
    "STRANGE THINGS.\n",
    "1) Using ```bits``` > 31 quantizes things with ```nan```. Why? Future work\n",
    "\n",
    "2) Always explicit the value of the keyword argument ```alpha``` of  ```quantized_bits()```, that is never leave the field blank, to avoid [strange behaviors](https://github.com/google/qkeras/issues/60)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set network hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User settings\n",
    "\n",
    "# BATCHNORM PARAMS\n",
    "fused_batchnorm = 1\n",
    "\n",
    "# POOL PARAMS\n",
    "pool_size_list = [(4, 4)]\n",
    "\n",
    "# 2DCONV PARAMS\n",
    "filters_list = [2, 3]\n",
    "kernel_size_list = [(3, 3), (3, 3)]\n",
    "strides_list = [(1, 1), (2, 2)]\n",
    "pads_list = [\"valid\", \"same\"]\n",
    "\n",
    "# DENSE PARAMS\n",
    "units_list = [10]\n",
    "\n",
    "# QUANTIZATION PARAMS\n",
    "bit_flat = 16\n",
    "\n",
    "bits_qactiv_list  = [bit_flat, bit_flat, bit_flat, bit_flat]\n",
    "bits_qweight_list = [bit_flat, bit_flat, bit_flat, 0       ] # last value is dummy\n",
    "\n",
    "#------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeLayer(Layer):\n",
    "\n",
    "    \"\"\"Subclass of Layer to create an Identity or Fake layer that does not exist for TensorFlow 2.4.0:\n",
    "    https://www.tensorflow.org/api_docs/python/tf/keras/layers/Identity\"\"\"\n",
    "    \n",
    "    def __init__(self, name=None):\n",
    "        super(FakeLayer, self).__init__(name=name)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case without fused BatchNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Keras model that we want to convert in QKeras\n",
    "BatchNorm is not folded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "pool (MaxPooling2D)          (None, 7, 7, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_0 (Conv2D)            (None, 5, 5, 2)           20        \n",
      "_________________________________________________________________\n",
      "relu_0 (ReLU)                (None, 5, 5, 2)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 3, 3, 3)           57        \n",
      "_________________________________________________________________\n",
      "bn_1 (BatchNormalization)    (None, 3, 3, 3)           12        \n",
      "_________________________________________________________________\n",
      "relu_1 (ReLU)                (None, 3, 3, 3)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 27)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                280       \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 369\n",
      "Trainable params: 363\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 10:35:39.810034: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "if fused_batchnorm == 1:\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "\n",
    "        MaxPooling2D(pool_size=pool_size_list[0], name=\"pool\"),\n",
    "\n",
    "        # Example of Conv2D without Batchnorm\n",
    "        Conv2D(filters=filters_list[0], kernel_size=kernel_size_list[0], strides=strides_list[0], padding=pads_list[0], name=\"conv2d_0\"),\n",
    "        ReLU(name=\"relu_0\"),\n",
    "\n",
    "        # Example of Conv2D with Batchnorm\n",
    "        Conv2D(filters_list[1], kernel_size_list[1], strides_list[1], pads_list[1], name=\"conv2d_1\"),\n",
    "        BatchNormalization(name=\"bn_1\"), # BatchNorm is not folded\n",
    "        ReLU(name=\"relu_1\"),\n",
    "\n",
    "        Flatten(name=\"flatten\"),\n",
    "\n",
    "        # Example of Dense without Batchnorm\n",
    "        Dense(units_list[0], name=\"dense\"),\n",
    "        Activation(\"softmax\", name=\"softmax\")\n",
    "\n",
    "    ])\n",
    "\n",
    "    model.build((None,input_width,input_width,input_channels))\n",
    "\n",
    "    model.compile(Adam(lr=0.001), loss=['categorical_crossentropy'], metrics=['accuracy'],\n",
    "                   run_eagerly=True)\n",
    "\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QKeras model with new activation layer \"quantized_bits_featuremap\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'use_batchnorm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43muse_batchnorm\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      3\u001b[0m     qmodel \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[1;32m      4\u001b[0m     \n\u001b[1;32m      5\u001b[0m         MaxPooling2D(pool_size\u001b[38;5;241m=\u001b[39mpool_size_list[\u001b[38;5;241m0\u001b[39m], name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpool\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m \n\u001b[1;32m     39\u001b[0m     ])\n\u001b[1;32m     41\u001b[0m     qmodel\u001b[38;5;241m.\u001b[39mbuild((\u001b[38;5;28;01mNone\u001b[39;00m,input_width,input_width,input_channels))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'use_batchnorm' is not defined"
     ]
    }
   ],
   "source": [
    "if fused_batchnorm == 0:\n",
    "    \n",
    "    qmodel = tf.keras.models.Sequential([\n",
    "    \n",
    "        MaxPooling2D(pool_size=pool_size_list[0], name=\"pool\"),\n",
    "        QActivation(\"quantized_bits_featuremap(bits=%s,integer=%s,symmetric=1,keep_negative=1,alpha='auto',scale_axis=0)\" % (bits_qactiv_list[0], bits_qactiv_list[0]), name=\"act_0\"),\n",
    "\n",
    "        # Example of Conv2D without Batchnorm\n",
    "        QConv2D(filters=filters_list[0], kernel_size=kernel_size_list[0], strides=strides_list[0], padding=pads_list[0], name=\"conv2d_0\",\n",
    "              kernel_quantizer=\"quantized_bits(%s,%s,1,1,alpha='auto')\" % (bits_qweight_list[0], bits_qweight_list[0]), \n",
    "              bias_quantizer=\"quantized_bits(31,31,1,1,alpha='auto')\"),\n",
    "              #activation=\"relu\"), # This way applies quantized_relu() that we do not want\n",
    "        ReLU(name=\"relu_0\"),\n",
    "        QActivation(\"quantized_bits_featuremap(%s,%s,1,1,alpha='auto',scale_axis=0)\" % (bits_qactiv_list[1], bits_qactiv_list[1]), name=\"act_1\"),\n",
    "\n",
    "        # Example of Conv2D with Batchnorm\n",
    "        #QConv2DBatchnorm(filters_list[1], kernel_size_list[1], strides_list[1], pads_list[1], name=\"conv2d_1\",\n",
    "        #      kernel_quantizer=\"quantized_bits(%s,%s,1,1,alpha='auto')\" % (bits_qweight_list[1], bits_qweight_list[1]), \n",
    "        #      bias_quantizer=\"quantized_bits(31,31,1,1,alpha='auto')\"),\n",
    "        #FakeLayer(name=\"bn_1\"),\n",
    "        QConv2D(filters=filters_list[1], kernel_size=kernel_size_list[1], strides=strides_list[1], padding=pads_list[1], name=\"conv2d_1\",\n",
    "              kernel_quantizer=\"quantized_bits(%s,%s,1,1,alpha='auto')\" % (bits_qweight_list[1], bits_qweight_list[1]), \n",
    "              bias_quantizer=\"quantized_bits(31,31,1,1,alpha='auto')\"),\n",
    "        BatchNormalization(name=\"bn_1\"),\n",
    "        ReLU(name=\"relu_1\"),\n",
    "        QActivation(\"quantized_bits_featuremap(%s,%s,1,1,alpha='auto',scale_axis=0)\" % (bits_qactiv_list[2], bits_qactiv_list[2]), name=\"act_2\"),\n",
    "\n",
    "        Flatten(name=\"flatten\"),\n",
    "\n",
    "        # Example of Dense without Batchnorm (scale_axis=2 for per-layer quantization)\n",
    "        QDense(units_list[0],\n",
    "             kernel_quantizer=\"quantized_bits(%s,%s,1,1,alpha='auto',scale_axis=2)\" % (bits_qweight_list[2], bits_qweight_list[2]),\n",
    "             bias_quantizer=\"quantized_bits(31,31,1,1,alpha='auto')\",\n",
    "             name=\"dense\"),\n",
    "        QActivation(\"quantized_bits_featuremap(%s,%s,1,1,alpha='auto',scale_axis=0)\" % (bits_qactiv_list[3], bits_qactiv_list[3]), name=\"act_3\"),\n",
    "\n",
    "        Activation(\"softmax\", name=\"softmax\")\n",
    "\n",
    "    ])\n",
    "\n",
    "    qmodel.build((None,input_width,input_width,input_channels))\n",
    "\n",
    "    qmodel.compile(Adam(lr=0.001), loss=['categorical_crossentropy'], metrics=['accuracy'],\n",
    "                   run_eagerly=True)\n",
    "\n",
    "    qmodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case with fused BN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Keras model that we want to convert in QKeras\n",
    "BatchNorm is folded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "pool (MaxPooling2D)          (None, 7, 7, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_0 (Conv2D)            (None, 5, 5, 2)           20        \n",
      "_________________________________________________________________\n",
      "relu_0 (ReLU)                (None, 5, 5, 2)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 3, 3, 3)           57        \n",
      "_________________________________________________________________\n",
      "relu_1 (ReLU)                (None, 3, 3, 3)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 27)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                280       \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 357\n",
      "Trainable params: 357\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if fused_batchnorm == 1:\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "\n",
    "        MaxPooling2D(pool_size=pool_size_list[0], name=\"pool\"),\n",
    "\n",
    "        # Example of Conv2D without Batchnorm\n",
    "        Conv2D(filters=filters_list[0], kernel_size=kernel_size_list[0], strides=strides_list[0], padding=pads_list[0], name=\"conv2d_0\"),\n",
    "        ReLU(name=\"relu_0\"),\n",
    "\n",
    "        # Example of Conv2D with Batchnorm\n",
    "        Conv2D(filters_list[1], kernel_size_list[1], strides_list[1], pads_list[1], name=\"conv2d_1\"),\n",
    "        #BatchNormalization(name=\"bn_1\"), # not needed because folded weights of qmodel will be transfered inside Conv2D\n",
    "        ReLU(name=\"relu_1\"),\n",
    "\n",
    "        Flatten(name=\"flatten\"),\n",
    "\n",
    "        # Example of Dense without Batchnorm\n",
    "        Dense(units_list[0], name=\"dense\"),\n",
    "        Activation(\"softmax\", name=\"softmax\")\n",
    "\n",
    "    ])\n",
    "\n",
    "    model.build((None,input_width,input_width,input_channels))\n",
    "\n",
    "    model.compile(Adam(lr=0.001), loss=['categorical_crossentropy'], metrics=['accuracy'],\n",
    "                   run_eagerly=True)\n",
    "\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QKeras model with new activation layer \"quantized_bits_featuremap\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "pool (MaxPooling2D)          (None, 7, 7, 1)           0         \n",
      "_________________________________________________________________\n",
      "act_0 (QActivation)          (None, 7, 7, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_0 (QConv2D)           (None, 5, 5, 2)           20        \n",
      "_________________________________________________________________\n",
      "relu_0 (ReLU)                (None, 5, 5, 2)           0         \n",
      "_________________________________________________________________\n",
      "act_1 (QActivation)          (None, 5, 5, 2)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (QConv2DBatchnorm)  (None, 3, 3, 3)           70        \n",
      "_________________________________________________________________\n",
      "bn_1 (FakeLayer)             (None, 3, 3, 3)           0         \n",
      "_________________________________________________________________\n",
      "relu_1 (ReLU)                (None, 3, 3, 3)           0         \n",
      "_________________________________________________________________\n",
      "act_2 (QActivation)          (None, 3, 3, 3)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 27)                0         \n",
      "_________________________________________________________________\n",
      "dense (QDense)               (None, 10)                280       \n",
      "_________________________________________________________________\n",
      "act_3 (QActivation)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 370\n",
      "Trainable params: 363\n",
      "Non-trainable params: 7\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if fused_batchnorm == 1:\n",
    "    \n",
    "    qmodel = tf.keras.models.Sequential([\n",
    "\n",
    "        MaxPooling2D(pool_size=pool_size_list[0], name=\"pool\"),\n",
    "        QActivation(\"quantized_bits_featuremap(bits=%s,integer=%s,symmetric=1,keep_negative=1,alpha='auto',scale_axis=0)\" % (bits_qactiv_list[0], bits_qactiv_list[0]), name=\"act_0\"),\n",
    "\n",
    "        # Example of Conv2D without Batchnorm\n",
    "        QConv2D(filters=filters_list[0], kernel_size=kernel_size_list[0], strides=strides_list[0], padding=pads_list[0], name=\"conv2d_0\",\n",
    "              kernel_quantizer=\"quantized_bits(%s,%s,1,1,alpha='auto')\" % (bits_qweight_list[0], bits_qweight_list[0]), \n",
    "              bias_quantizer=\"quantized_bits(31,31,1,1,alpha='auto')\"),\n",
    "              #activation=\"relu\"), # This way applies quantized_relu() that we do not want\n",
    "        ReLU(name=\"relu_0\"),\n",
    "        QActivation(\"quantized_bits_featuremap(%s,%s,1,1,alpha='auto',scale_axis=0)\" % (bits_qactiv_list[1], bits_qactiv_list[1]), name=\"act_1\"),\n",
    "\n",
    "        # Example of Conv2D with fused Batchnorm\n",
    "        QConv2DBatchnorm(filters_list[1], kernel_size_list[1], strides_list[1], pads_list[1], name=\"conv2d_1\",\n",
    "              kernel_quantizer=\"quantized_bits(%s,%s,1,1,alpha='auto')\" % (bits_qweight_list[1], bits_qweight_list[1]), \n",
    "              bias_quantizer=\"quantized_bits(31,31,1,1,alpha='auto')\"),\n",
    "        FakeLayer(name=\"bn_1\"),\n",
    "        #QConv2D(filters=filters_list[1], kernel_size=kernel_size_list[1], strides=strides_list[1], padding=pads_list[1], name=\"conv2d_1\",\n",
    "        #      kernel_quantizer=\"quantized_bits(%s,%s,1,1,alpha='auto')\" % (bits_qweight_list[1], bits_qweight_list[1]), \n",
    "        #      bias_quantizer=\"quantized_bits(31,31,1,1,alpha='auto')\"),\n",
    "        #BatchNormalization(name=\"bn_1\"),\n",
    "        ReLU(name=\"relu_1\"),\n",
    "        QActivation(\"quantized_bits_featuremap(%s,%s,1,1,alpha='auto',scale_axis=0)\" % (bits_qactiv_list[2], bits_qactiv_list[2]), name=\"act_2\"),\n",
    "\n",
    "        Flatten(name=\"flatten\"),\n",
    "\n",
    "        # Example of Dense without Batchnorm (scale_axis=2 for per-layer quantization)\n",
    "        QDense(units_list[0],\n",
    "             kernel_quantizer=\"quantized_bits(%s,%s,1,1,alpha='auto',scale_axis=2)\" % (bits_qweight_list[2], bits_qweight_list[2]),\n",
    "             bias_quantizer=\"quantized_bits(31,31,1,1,alpha='auto')\",\n",
    "             name=\"dense\"),\n",
    "        QActivation(\"quantized_bits_featuremap(%s,%s,1,1,alpha='auto',scale_axis=0)\" % (bits_qactiv_list[3], bits_qactiv_list[3]), name=\"act_3\"),\n",
    "\n",
    "        Activation(\"softmax\", name=\"softmax\")\n",
    "\n",
    "    ])\n",
    "\n",
    "    qmodel.build((None,input_width,input_width,input_channels))\n",
    "\n",
    "    qmodel.compile(Adam(lr=0.001), loss=['categorical_crossentropy'], metrics=['accuracy'],\n",
    "                   run_eagerly=True)\n",
    "\n",
    "    qmodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and save qmodel OR load qmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 8s 92ms/step - loss: 2.2782 - accuracy: 0.1796 - val_loss: 2.1979 - val_accuracy: 0.3359\n",
      "Model saved correctly\n"
     ]
    }
   ],
   "source": [
    "# User settings\n",
    "\n",
    "train_model = 1\n",
    "epochs = 1\n",
    "\n",
    "save_model  = 1\n",
    "\n",
    "if fused_batchnorm == 0:\n",
    "    save_path = \"./qmodel\"\n",
    "else:\n",
    "    save_path = \"./qmodel_fusedbatchnorm\"\n",
    "    \n",
    "#------------------------------------------\n",
    "\n",
    "if train_model == 1:\n",
    "    \n",
    "    qmodel.fit(x_train, y_train, batch_size=512,\n",
    "               epochs=epochs, validation_split=0.25, shuffle=True)    \n",
    "    \n",
    "if save_model == 1:\n",
    "\n",
    "    qmodel.save_weights(save_path, overwrite=True, save_format=\"tf\")\n",
    "    os.remove(\"./checkpoint\")\n",
    "\n",
    "    print(\"Model saved correctly\")\n",
    "\n",
    "else:\n",
    "    \n",
    "    qmodel.load_weights(save_path, by_name=False).expect_partial()\n",
    "    \n",
    "    print(\"Model loaded correctly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer weights from qmodel to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def my_evaluate(predictions, y):\n",
    "    index_pred = np.argmax(predictions)\n",
    "    #print(index_pred)\n",
    "    index_gold = np.argmax(y)\n",
    "    #print(index_gold)\n",
    "    if index_pred != index_gold:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1 # 1 when correct\n",
    "    \n",
    "qlayers = []\n",
    "for qlayer in qmodel.layers:\n",
    "    if qlayer.get_weights():\n",
    "        qlayers.append(qlayer)\n",
    "\n",
    "layers = []\n",
    "for layer in model.layers:\n",
    "    if layer.get_weights():\n",
    "        layers.append(layer)\n",
    "\n",
    "for qlayer, layer in zip(qlayers, layers):\n",
    "    \n",
    "    with io.capture_output(stdout=True, stderr=False) as captured: # to disable all the printings to stdout of the functions inside this statement: https://stackoverflow.com/questions/23610585/ipython-notebook-avoid-printing-within-a-function/23611571#23611571\n",
    "        \n",
    "        print(qlayer.__class__.__name__)\n",
    "\n",
    "        if qlayer.get_weights():\n",
    "            \n",
    "            print(qlayer.name)\n",
    "            print(\"qlayer.get_weights()[0].shape:\", qlayer.get_weights()[0].shape)\n",
    "            print(\"qlayer.get_weights()[1].shape:\", qlayer.get_weights()[1].shape)\n",
    "            print(\"layer.get_weights()[0].shape:\", layer.get_weights()[0].shape)\n",
    "            print(\"layer.get_weights()[1].shape:\", layer.get_weights()[1].shape)\n",
    "            try:\n",
    "                print(\"This layer IS FOLDED\")\n",
    "                extracted_weights = qlayer.get_folded_weights()\n",
    "            except:\n",
    "                print(\"This layer is NOT folded\")\n",
    "                extracted_weights = qlayer.get_weights()[0:2]\n",
    "            \n",
    "            print(\"layer.get_weights()[0][0] MODEL BEFORE\")\n",
    "            print(layer.get_weights()[0][0])\n",
    "            print(\"layer.get_weights()[1] MODEL BEFORE\")\n",
    "            print(layer.get_weights()[1])\n",
    "            layer.set_weights(copy.deepcopy(extracted_weights))\n",
    "            print(\"layer.get_weights()[0][0] MODEL AFTER\")\n",
    "            print(layer.get_weights()[0][0])\n",
    "            print(\"layer.get_weights()[1] MODEL AFTER\")\n",
    "            print(layer.get_weights()[1])\n",
    "            \n",
    "            try:\n",
    "                print(\"qlayer.get_folded_weights()[0][0] QMODEL\")\n",
    "                print(qlayer.get_folded_weights()[0][0])\n",
    "                print(\"qlayer.get_folded_weights()[1] QMODEL\")\n",
    "                print(qlayer.get_folded_weights()[1])\n",
    "            except:\n",
    "                print(\"qlayer.get_weights()[0][0] QMODEL\")\n",
    "                print(qlayer.get_weights()[0][0])\n",
    "                print(\"qlayer.get_weights()[1] QMODEL\")\n",
    "                print(qlayer.get_weights()[1])\n",
    "            \n",
    "            result = layer.get_weights()[0:2]\n",
    "            if not np.array_equal(layer.get_weights()[0], extracted_weights[0]) or \\\n",
    "               not np.array_equal(layer.get_weights()[1], extracted_weights[1]):\n",
    "                raise Exception(\"Transfer weights failed\")\n",
    "\n",
    "        print(\"------------\")\n",
    "    \n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a class=\"anchor\" id=\"ch2\"></a>\n",
    "# 2) Run inference and compare model with qmodel\n",
    "\n",
    "Go to next: [Ch. 3](#ch3).\n",
    "\n",
    "Go to others: [Ch. 0](#ch0), [Ch. 1](#ch1), [Ch. 2](#ch2), [Ch. 3](#ch3), [Ch. 4](#ch4).\n",
    "\n",
    "Go to [Top](#top)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tot_layers: 3\n",
      "\n",
      "pred_model:\n",
      " [[0.08166327762123432 0.11003845310922074 0.1102875281852346\n",
      "  0.10469012510970352 0.11194652781578386 0.07747798227928071\n",
      "  0.08967536025645619 0.10162231098122625 0.1023007066299291\n",
      "  0.11029772801193076]]\n",
      "pred_qmodel:\n",
      " [[0.08166210797755116 0.11003865537847819 0.11028714046758051\n",
      "  0.10468833425496651 0.11194829896838986 0.07747769993940262\n",
      "  0.08967631103214418 0.10162261859998888 0.10230046984195451\n",
      "  0.11029836353954361]]\n",
      "test_acc_model:    0\n",
      "test_acc_qmodel:   0\n",
      "iteration 1/25\n",
      "-------------------------\n",
      "\n",
      "pred_model:\n",
      " [[0.1042725359931888  0.10083896718446902 0.09600214298662138\n",
      "  0.11581453392236682 0.09156329416462501 0.10617030608081972\n",
      "  0.10049797530476413 0.08665035673670321 0.10089699498676892\n",
      "  0.09729289263967292]]\n",
      "pred_qmodel:\n",
      " [[0.10427433659702608 0.10083774794910334 0.09600130042474907\n",
      "  0.11581227425221213 0.09156442415399206 0.10616985267592864\n",
      "  0.10049920881558476 0.0866523926332558  0.10089509910310229\n",
      "  0.09729336339504578]]\n",
      "test_acc_model:    0\n",
      "test_acc_qmodel:   0\n",
      "iteration 2/25\n",
      "-------------------------\n",
      "\n",
      "pred_model:\n",
      " [[0.10485543979419133 0.13910758765271763 0.10399063233832355\n",
      "  0.0950294111199183  0.07406102501404078 0.10633354233519361\n",
      "  0.0837784337970058  0.10459834429653156 0.08607888856724437\n",
      "  0.10216669508483321]]\n",
      "pred_qmodel:\n",
      " [[0.10485642348826346 0.1391093856858057  0.10398989323919577\n",
      "  0.09503138702637452 0.07406153682895779 0.10633458794609281\n",
      "  0.08377663161825107 0.10459926345298828 0.0860769310542324\n",
      "  0.10216395965983824]]\n",
      "test_acc_model:    1\n",
      "test_acc_qmodel:   1\n",
      "iteration 3/25\n",
      "-------------------------\n",
      "\n",
      "pred_model:\n",
      " [[0.10899484561560664 0.07754453499671693 0.09564915818804734\n",
      "  0.10789448343120672 0.10687486124039422 0.08933439864980405\n",
      "  0.11104400130729478 0.09346450378859479 0.10390950873452\n",
      "  0.10528970404781456]]\n",
      "pred_qmodel:\n",
      " [[0.10899628591364388 0.07754408472956928 0.0956490684629267\n",
      "  0.10789432503556455 0.1068758378015071  0.08933281717392308\n",
      "  0.11104356229131586 0.0934661097608779  0.10390867354998533\n",
      "  0.10528923528068637]]\n",
      "test_acc_model:    0\n",
      "test_acc_qmodel:   0\n",
      "iteration 4/25\n",
      "-------------------------\n",
      "\n",
      "pred_model:\n",
      " [[0.11037564170549077 0.08981118849470546 0.07635613295418274\n",
      "  0.11868258820465569 0.1369166897924104  0.09909498262965236\n",
      "  0.1043275500306405  0.07088937560382214 0.10040115162931398\n",
      "  0.09314469895512603]]\n",
      "pred_qmodel:\n",
      " [[0.11037613596221105 0.08981035520711422 0.07635655277293452\n",
      "  0.1186813958695388  0.13691696286298635 0.09909477113746322\n",
      "  0.10432858732725933 0.07088995468299208 0.10040042285172103\n",
      "  0.09314486132577945]]\n",
      "test_acc_model:    1\n",
      "test_acc_qmodel:   1\n",
      "iteration 5/25\n",
      "-------------------------\n",
      "\n",
      "pred_model:\n",
      " [[0.11183078976390257 0.1280734005508366  0.10216756414821769\n",
      "  0.09220373870668504 0.08010899824166835 0.09335015748977753\n",
      "  0.0896175336998675  0.098518516068783   0.09713081184208942\n",
      "  0.10699848948817225]]\n",
      "pred_qmodel:\n",
      " [[0.11183082533460867 0.12807504408776982 0.10216760434527004\n",
      "  0.09220270414473833 0.08010906776551509 0.09334957401546871\n",
      "  0.08961683228209828 0.09851877000210735 0.09712933594263924\n",
      "  0.10700024207978436]]\n",
      "test_acc_model:    1\n",
      "test_acc_qmodel:   1\n",
      "iteration 6/25\n",
      "-------------------------\n",
      "\n",
      "pred_model:\n",
      " [[0.08937624774311324 0.10453577438257754 0.085508942083469\n",
      "  0.10624741282432966 0.13605434005644876 0.09347840850873632\n",
      "  0.09209500893055127 0.08716395143998523 0.08664394903245669\n",
      "  0.11889596499833217]]\n",
      "pred_qmodel:\n",
      " [[0.08937606329976153 0.10453561057840942 0.08550926391157487\n",
      "  0.10624576254032012 0.13605538965305541 0.09347717172045603\n",
      "  0.09209473617912087 0.08716494556678975 0.08664413013686556\n",
      "  0.11889692641364637]]\n",
      "test_acc_model:    1\n",
      "test_acc_qmodel:   1\n",
      "iteration 7/25\n",
      "-------------------------\n",
      "\n",
      "pred_model:\n",
      " [[0.10039248970123826 0.08782771570772988 0.10020449036661336\n",
      "  0.11547869468504657 0.10044819860957382 0.0907755710226736\n",
      "  0.1029326315375186  0.0933046156496593  0.10176144352045792\n",
      "  0.10687414919948873]]\n",
      "pred_qmodel:\n",
      " [[0.10039235073433589 0.08782710733701737 0.10020410916953204\n",
      "  0.11547737588184699 0.10044879131572676 0.09077556691939002\n",
      "  0.10293336454005333 0.09330465541844292 0.10176184641893113\n",
      "  0.10687483226472363]]\n",
      "test_acc_model:    0\n",
      "test_acc_qmodel:   0\n",
      "iteration 8/25\n",
      "-------------------------\n",
      "\n",
      "pred_model:\n",
      " [[0.10379304830231985 0.08238372377745401 0.09820680498913159\n",
      "  0.11408827609294629 0.10645741270865033 0.08747529005025345\n",
      "  0.10205289889531574 0.09443755501324066 0.10712546356402886\n",
      "  0.10397952660665918]]\n",
      "pred_qmodel:\n",
      " [[0.1037933384209371  0.08238326378178971 0.0982069020705509\n",
      "  0.11408781462376405 0.10645744151534231 0.08747486972352576\n",
      "  0.10205344878088546 0.09443792414895576 0.10712574162398956\n",
      "  0.10397925531025931]]\n",
      "test_acc_model:    0\n",
      "test_acc_qmodel:   0\n",
      "iteration 9/25\n",
      "-------------------------\n",
      "\n",
      "pred_model:\n",
      " [[0.10488359730808589 0.08416352897437583 0.093303534129278\n",
      "  0.10315526568905574 0.11139596892572659 0.07412794864407857\n",
      "  0.0989606188397959  0.10755937149934931 0.10563525220682214\n",
      "  0.11681491378343208]]\n",
      "pred_qmodel:\n",
      " [[0.10488449196769865 0.0841631534858997  0.09330324893574114\n",
      "  0.10315406920968367 0.11139640986954819 0.0741274927707523\n",
      "  0.09896065438284739 0.10755948078835605 0.10563581538497321\n",
      "  0.11681518320449971]]\n",
      "test_acc_model:    1\n",
      "test_acc_qmodel:   1\n",
      "iteration 10/25\n",
      "-------------------------\n",
      "\n",
      "pred_model:\n",
      " [[0.16502320432094092 0.1258699883328119  0.07567569190008779\n",
      "  0.09800602135265114 0.09739587392753887 0.0864615157908274\n",
      "  0.11879956183957709 0.06535811626275034 0.08967041173947342\n",
      "  0.07773961453334126]]\n",
      "pred_qmodel:\n",
      " [[0.16501905753162363 0.12587045781647704 0.07567942283682336\n",
      "  0.0980067763837128  0.09739471706188076 0.08645952385033766\n",
      "  0.1188002821750498  0.06535711960461772 0.0896732579821752\n",
      "  0.07773938475730205]]\n",
      "test_acc_model:    1\n",
      "test_acc_qmodel:   1\n",
      "iteration 11/25\n",
      "-------------------------\n",
      "\n",
      "pred_model:\n",
      " [[0.11644685235803802 0.06574339347031198 0.09581213827113276\n",
      "  0.09812361406520739 0.11384229020883842 0.0861264299769539\n",
      "  0.11573575579117665 0.09936689673734889 0.10204910588158088\n",
      "  0.10675352323941115]]\n",
      "pred_qmodel:\n",
      " [[0.11644757339077745 0.0657433154480197  0.09581238108493015\n",
      "  0.09812229849205921 0.11384337395333743 0.08612569512013016\n",
      "  0.1157347650776835  0.09936771762508627 0.10204920878247324\n",
      "  0.10675367102550269]]\n",
      "test_acc_model:    0\n",
      "test_acc_qmodel:   0\n",
      "iteration 12/25\n",
      "-------------------------\n",
      "\n",
      "pred_model:\n",
      " [[0.09143316060993219 0.09919012438425068 0.09238363099568594\n",
      "  0.10289182446895884 0.10587491520676745 0.07818328333666673\n",
      "  0.10299542101750411 0.10242571777168234 0.10232959832175295\n",
      "  0.12229232388679874]]\n",
      "pred_qmodel:\n",
      " [[0.09143263873456674 0.09919022895086282 0.0923832349956305\n",
      "  0.10288986724871388 0.10587645903412639 0.07818233437308192\n",
      "  0.10299517075367247 0.10242606312054901 0.1023307911169786\n",
      "  0.1222932116718177 ]]\n",
      "test_acc_model:    1\n",
      "test_acc_qmodel:   1\n",
      "iteration 13/25\n",
      "-------------------------\n",
      "\n",
      "pred_model:\n",
      " [[0.1410429831844609  0.10864930982195264 0.07600440388155645\n",
      "  0.11697191509276363 0.09988691532335321 0.09566701980668962\n",
      "  0.10269891824951095 0.08062534768447693 0.08553232342958524\n",
      "  0.09292086352565036]]\n",
      "pred_qmodel:\n",
      " [[0.14104521735932266 0.10864958384950538 0.07600432510072565\n",
      "  0.11697216084013994 0.09988663349041636 0.09566389393687268\n",
      "  0.10269990841317407 0.08062583561749372 0.08553050911666228\n",
      "  0.092921932275687  ]]\n",
      "test_acc_model:    1\n",
      "test_acc_qmodel:   1\n",
      "iteration 14/25\n",
      "-------------------------\n",
      "\n",
      "pred_model:\n",
      " [[0.10061216536626212 0.14885997305557114 0.08859944696326322\n",
      "  0.08311466559059635 0.08920477257594957 0.06690849304319073\n",
      "  0.08190426255587054 0.10805771438691728 0.10525463436003335\n",
      "  0.12748387210234566]]\n",
      "pred_qmodel:\n",
      " [[0.10061081931771972 0.14885822117442457 0.08859977973908566\n",
      "  0.08311547475385805 0.08920548913876652 0.0669088724690687\n",
      "  0.08190461687105663 0.10805874443844052 0.10525359067277061\n",
      "  0.12748439142480894]]\n",
      "test_acc_model:    1\n",
      "test_acc_qmodel:   1\n",
      "iteration 15/25\n",
      "-------------------------\n",
      "\n",
      "pred_model:\n",
      " [[0.10508473110825349 0.11067405468995567 0.09838017551256226\n",
      "  0.11749843846606743 0.0861120209667731  0.1124237642100218\n",
      "  0.09266246987341323 0.08219355952794677 0.08791708704657009\n",
      "  0.1070536985984362 ]]\n",
      "pred_qmodel:\n",
      " [[0.10508559299168323 0.11067451956176874 0.09837971103081045\n",
      "  0.11749620911641746 0.0861117792459462  0.11242302599288646\n",
      "  0.09266376125332375 0.08219234068849318 0.08791851853261727\n",
      "  0.10705454158605318]]\n",
      "test_acc_model:    0\n",
      "test_acc_qmodel:   0\n",
      "iteration 16/25\n",
      "-------------------------\n",
      "\n",
      "pred_model:\n",
      " [[0.10537341667543797 0.09297334878092968 0.09114120968641728\n",
      "  0.09865555461221925 0.11437605326988817 0.07324605966058331\n",
      "  0.1020165934004527  0.10409609908956752 0.10391028856042563\n",
      "  0.11421137626407846]]\n",
      "pred_qmodel:\n",
      " [[0.10537429532855849 0.0929739865824541  0.09114107284761457\n",
      "  0.09865308260354198 0.11437732536085135 0.07324476584732655\n",
      "  0.10201739230020798 0.10409643926578308 0.1039102445930588\n",
      "  0.11421139527060313]]\n",
      "test_acc_model:    0\n",
      "test_acc_qmodel:   0\n",
      "iteration 17/25\n",
      "-------------------------\n",
      "\n",
      "pred_model:\n",
      " [[0.08094716142512651 0.11679583976854543 0.10943268496220615\n",
      "  0.09517616190172297 0.11395395086796947 0.07154256287285705\n",
      "  0.09074262624436188 0.10949664873346934 0.10395585184331999\n",
      "  0.10795651138042124]]\n",
      "pred_qmodel:\n",
      " [[0.08094662883817136 0.11679380015602632 0.10943460663243282\n",
      "  0.09517734276380921 0.113954329918326   0.07154320974459685\n",
      "  0.09074267617581759 0.10949551663024615 0.10395689392732553\n",
      "  0.10795499521324822]]\n",
      "test_acc_model:    0\n",
      "test_acc_qmodel:   0\n",
      "iteration 18/25\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pred_model:\n",
      " [[0.10522931676729716 0.08476616690050633 0.09536652025384872\n",
      "  0.11573699123813039 0.1062677394360275  0.09077106400673564\n",
      "  0.10154239767672268 0.09139534306896119 0.10566319942857752\n",
      "  0.10326126122319286]]\n",
      "pred_qmodel:\n",
      " [[0.10523027804812343 0.08476558239181815 0.09536661363185389\n",
      "  0.11573600954513406 0.10626819546011404 0.09077041903741782\n",
      "  0.10154267336514147 0.09139593163339425 0.10566302031218192\n",
      "  0.103261276574821  ]]\n",
      "test_acc_model:    1\n",
      "test_acc_qmodel:   1\n",
      "iteration 19/25\n",
      "-------------------------\n",
      "\n",
      "pred_model:\n",
      " [[0.10128501837553783 0.08259465248402285 0.10219341169315627\n",
      "  0.11437753908007932 0.10190382753642734 0.0899056834366001\n",
      "  0.10224147882364705 0.09591269669506128 0.1037327636560549\n",
      "  0.10585292821941308]]\n",
      "pred_qmodel:\n",
      " [[0.10128518555899518 0.08259604634716332 0.10219328232670534\n",
      "  0.11437658648041742 0.10190355981347865 0.08990529125829894\n",
      "  0.10224147091366582 0.0959125969625388  0.1037325125965382\n",
      "  0.1058534677421982 ]]\n",
      "test_acc_model:    0\n",
      "test_acc_qmodel:   0\n",
      "iteration 20/25\n",
      "-------------------------\n",
      "\n",
      "pred_model:\n",
      " [[0.09066883424138385 0.10483603347646153 0.1078949694781793\n",
      "  0.09827916103002597 0.09356710584915036 0.08362058812455697\n",
      "  0.09276326182629006 0.10614887538370178 0.09153038017075411\n",
      "  0.1306907904194959 ]]\n",
      "pred_qmodel:\n",
      " [[0.09066934542746855 0.10483603042683705 0.10789550797813721\n",
      "  0.09827814517832721 0.09356760073581748 0.08362036432727873\n",
      "  0.09276353556680497 0.10614897179887053 0.09153071574446221\n",
      "  0.130689782815996  ]]\n",
      "test_acc_model:    1\n",
      "test_acc_qmodel:   1\n",
      "iteration 21/25\n",
      "-------------------------\n",
      "\n",
      "pred_model:\n",
      " [[0.10318130548455753 0.08081920717534227 0.09558594995498948\n",
      "  0.10961586878314408 0.10035439813464768 0.08943162963727656\n",
      "  0.11710433493734068 0.09319826643247815 0.10125140447626174\n",
      "  0.10945763498396163]]\n",
      "pred_qmodel:\n",
      " [[0.10318128187650773 0.08081948002648365 0.09558588964950068\n",
      "  0.10961549939470012 0.10035461739892335 0.08943146672895969\n",
      "  0.11710409883076305 0.09319818872933008 0.1012518035798439\n",
      "  0.10945767378498776]]\n",
      "test_acc_model:    1\n",
      "test_acc_qmodel:   1\n",
      "iteration 22/25\n",
      "-------------------------\n",
      "\n",
      "pred_model:\n",
      " [[0.10313946710674825 0.08729806064451931 0.09463956796515355\n",
      "  0.10897423792398661 0.1131388958981702  0.09047135699466949\n",
      "  0.0986627876425867  0.09054416672884727 0.09684472837241037\n",
      "  0.11628673072290824]]\n",
      "pred_qmodel:\n",
      " [[0.10313974562053244 0.08729771516430102 0.09463960309233745\n",
      "  0.10897293013630183 0.11313947982563574 0.09046941551153878\n",
      "  0.09866373795254346 0.09054546981060886 0.09684510198009777\n",
      "  0.1162868009061026 ]]\n",
      "test_acc_model:    0\n",
      "test_acc_qmodel:   0\n",
      "iteration 23/25\n",
      "-------------------------\n",
      "\n",
      "pred_model:\n",
      " [[0.09927060804167001 0.08677764674192508 0.09620796079670217\n",
      "  0.11507874202253791 0.09725194607337756 0.09245138271713768\n",
      "  0.11022050150649693 0.08757688037076627 0.10796262189785209\n",
      "  0.1072017098315343 ]]\n",
      "pred_qmodel:\n",
      " [[0.09927060360208016 0.08677769861334225 0.09620809922198965\n",
      "  0.1150783184700779  0.09725171963545019 0.09245129977685836\n",
      "  0.11022057571890123 0.08757707657334016 0.10796288194633089\n",
      "  0.10720172644162922]]\n",
      "test_acc_model:    0\n",
      "test_acc_qmodel:   0\n",
      "iteration 24/25\n",
      "-------------------------\n",
      "\n",
      "pred_model:\n",
      " [[0.12026734698967743 0.0793351226747094  0.08729112064031835\n",
      "  0.10910630780160165 0.1208447507928519  0.0921475204212236\n",
      "  0.10585391343693444 0.08427849174372638 0.09466484194749165\n",
      "  0.10621058355146516]]\n",
      "pred_qmodel:\n",
      " [[0.12026780746297908 0.0793351796973812  0.08729163344260049\n",
      "  0.10910535762630397 0.12084513166264343 0.09214653908927065\n",
      "  0.10585390636796586 0.08427890784584406 0.09466433787607208\n",
      "  0.10621119892893921]]\n",
      "test_acc_model:    1\n",
      "test_acc_qmodel:   1\n",
      "iteration 25/25\n",
      "-------------------------\n",
      "-------------------------\n",
      "TOT iterations:         25\n",
      "TOT test_acc_model:     0.52\n",
      "TOT test_acc_qmodel:    0.52\n"
     ]
    }
   ],
   "source": [
    "# User settings\n",
    "\n",
    "samples_to_run = 25\n",
    "\n",
    "offset = 0\n",
    "min_samples = offset\n",
    "max_samples = offset+samples_to_run\n",
    "\n",
    "print_prediction = True\n",
    "\n",
    "#------------------------------------------\n",
    "\n",
    "tot_layers = 0\n",
    "for layer in qmodel.layers:\n",
    "    if layer.get_weights():\n",
    "        tot_layers += 1\n",
    "print(\"tot_layers:\", tot_layers)\n",
    "\n",
    "iterations = 0\n",
    "test_acc_accumulator_model = 0\n",
    "test_acc_accumulator_qmodel = 0\n",
    "\n",
    "for x, y in zip(x_test[min_samples:max_samples], y_test[min_samples:max_samples]):\n",
    "        \n",
    "    x_reshaped = x.reshape(1, x.shape[0], x.shape[1], x.shape[2])\n",
    "    \n",
    "    # Predict the samples with model, i.e. the Keras model\n",
    "    pred_model = np.asarray(model.predict(x_reshaped, batch_size=1, verbose=0), dtype=np.float64)\n",
    "\n",
    "    # Predict the samples with qmodel, i.e. the modified QKeras model\n",
    "    pred_qmodel = np.asarray(qmodel.predict(x_reshaped, batch_size=1, verbose=0), dtype=np.float64)\n",
    "    \n",
    "    # Calculate test accuracy\n",
    "    test_acc_model  = my_evaluate(pred_model,  y)\n",
    "    test_acc_qmodel = my_evaluate(pred_qmodel, y)\n",
    "\n",
    "    if print_prediction == True:\n",
    "        \n",
    "        print(\"\\npred_model:\\n\", pred_model)\n",
    "        print(\"pred_qmodel:\\n\", pred_qmodel)\n",
    "        \n",
    "        print(\"test_acc_model:   \", test_acc_model)\n",
    "        print(\"test_acc_qmodel:  \", test_acc_qmodel)\n",
    "        \n",
    "    test_acc_accumulator_model  += test_acc_model\n",
    "    test_acc_accumulator_qmodel += test_acc_qmodel\n",
    "\n",
    "    iterations = iterations + 1\n",
    "    \n",
    "    if print_prediction == True:\n",
    "        print(\"iteration %d/%d\" % (iterations, (max_samples - min_samples)))\n",
    "        print(\"-------------------------\")\n",
    "    \n",
    "print(\"-------------------------\")\n",
    "\n",
    "print(\"TOT iterations:        \", iterations)\n",
    "print(\"TOT test_acc_model:    \", test_acc_accumulator_model/iterations)\n",
    "print(\"TOT test_acc_qmodel:   \", test_acc_accumulator_qmodel/iterations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***\n",
    "<a class=\"anchor\" id=\"ch3\"></a>\n",
    "# 3) Extract QKeras quantization factors\n",
    "Go to next: [Ch. 4](#ch4).\n",
    "\n",
    "Go to others: [Ch. 0](#ch0), [Ch. 1](#ch1), [Ch. 2](#ch2), [Ch. 3](#ch3), [Ch. 4](#ch4).\n",
    "\n",
    "Go to [Top](#top).\n",
    "\n",
    "This is the complete quantization formula for a matrix multiplication operation (valid also for an FC layer) taken from [[3]#Quantized-Matrix-Multiplication-Mathematics](#https://leimao.github.io/article/Neural-Networks-Quantization/#Quantized-Matrix-Multiplication-Mathematics) (an equivalent version is Eq.7 in [2]):\n",
    "$$\\begin{align} Y_{q,i,j} &= z_Y + \\frac{s_b}{s_Y} (b_{q, j} - z_b) + \\frac{s_X s_W}{s_Y} \\Bigg[ \\bigg( \\sum_{k=1}^{p} X_{q,i,k} W_{q, k,j} \\bigg) - \\bigg( z_W \\sum_{k=1}^{p} X_{q,i,k} \\bigg) - \\bigg( z_X \\sum_{k=1}^{p} W_{q, k,j} \\bigg) + p z_X z_W\\Bigg] \\end{align}$$\n",
    "\n",
    "There are some contributions that could be deleted if the <b>zero points</b> of weights ```z_w``` and biases ```z_b``` <b>are forced to be zero, i.e. if both the quantized range and the fake-quantized/floating-point range of weights and biases, respectively, are symmetric</b>. When this happens, affine quantization mapping is called scale quantization mapping [3]. It is relatively easy to set the quantized range to be symmetric (for example, in QKeras we just need to pass ```quantized_bits()``` with ```symmetric=1``` and ```keep_negative=1``` to both the arguments ```kernel_quantizer``` and ```bias_quantizer``` of each QKeras layer), but this is not the case for the fake-quantized/floating-point range. There are two ways to make the latter symmetric:\n",
    "\n",
    "1) during training, by constraining weight and bias tensors to a given symmetric range of values;\n",
    "\n",
    "2) during training, by using a different way to calculate the scaling factor ```s```. Instead of calculating it in the standard and more general way: \n",
    "$$\\begin{align} s &= \\frac{\\beta - \\alpha}{\\beta_q - \\alpha_q}\\end{align},$$\n",
    "it can be calculated as: \n",
    "$$\\begin{align} s &= \\frac{2 * max (abs (tensor) )}{\\beta_q - \\alpha_q}\\end{align},$$\n",
    "where ```tensor``` is the floating-point weight/bias tensor to be quantized, ```[alpha; beta]``` is the floating-point range (where in turns ```alpha``` and ```beta``` are the minimum and maximum values of the entire tensor, so there is only one scalar ```s``` for the entire tensor), ```[alphaq; betaq]``` is the quantized range (which depends on the number of bits we want to represent the quantized data). Regarding the operations, ```abs()``` calculates the absolute value of all the elements in ```tensor``` and ```max``` extracts the maximum value from each channel (so in the second formula ```s``` is an array of scaling factors). Apart from the difference related to the per-layer vs per-channel quantization, the second formula is more general because removes the constraint of searching for the minimum in the tensor and directly assumes that the floating-point range (numerator) is symmetric, even if it is not actually true, but in this way it avoids to constrain ```alpha``` and ```beta``` to be exactly equal and opposite.\n",
    "\n",
    "[TensorFlow Lite states](https://www.tensorflow.org/lite/performance/quantization_spec#symmetric_vs_asymmetric) that they are forcing the zero points to zero, but they do not show how (maybe it is necessary to look at the source code: future work). [This guy](https://stackoverflow.com/questions/69746834/tf-lite-model-force-symmetric-filter-weights-in-fully-connected-layers) tried to implement the first approach using [tf.keras.constraints](https://www.tensorflow.org/api_docs/python/tf/keras/constraints) without success; instead QKeras follows the second approach, as you can see in source code of ```quantized_bits()``` in [quantizers.py#L586](https://github.com/google/qkeras/blob/b91d8815b31f05ddf9c7b6d62381df9be72a570a/qkeras/quantizers.py#L586).\n",
    "\n",
    "In the light of the aforementioned, in the next cells of this notebook we will extract and save to .txt files only the following quantization parameters that will be used for the inference in hardware (discussed in [Chapter 3](#ch3)):\n",
    "\n",
    "- ```fq```, ```scale_f```, ```zeropoint_f``` and ```[alphaq_f, betaq_f]``` are the quantized values, the scaling factors, the zero points and the quantized range of the corresponding output features of a QActivation layer used for the q-deq operation, respectively;\n",
    "\n",
    "- ```wq``` and ```scale_w``` are the quantized weights and their scaling factors; \n",
    "\n",
    "- ```bq``` and ```scale_b``` are the quantized biases and their scaling factors;\n",
    "\n",
    "- ```subq1``` is the third term in the squared brackets in the quantization formula above (i.e. the summation over the quantized weights multiplied by the zero point of the input features):\n",
    "$$\\bigg( z_X \\sum_{k=1}^{p} W_{q, k,j} \\bigg)$$\n",
    "\n",
    "To run the notebook without issues, you should edit the file [quantizers.py](https://github.com/google/qkeras/blob/b91d8815b31f05ddf9c7b6d62381df9be72a570a/qkeras/quantizers.py) to expose the following internal variables to the external world as attributes. To ease this step, just follow the instructions in the readme file of this repo:\n",
    "\n",
    "- ```m_i = K.cast_to_floatx(K.pow(2, self.integer))```;\n",
    "\n",
    "- ```alphaq = -2**(self.bits-1)+1 if self.symmetric else 0```;\n",
    "\n",
    "- ```betaq = 2**(self.bits-1)-1 if self.symmetric else (2**self.bits)-1```;\n",
    "\n",
    "- ```scale1 = (K.max(abs(x), axis=axis, keepdims=True) * 2) / levels```.\n",
    "\n",
    "In particular, we need ```m_i``` and ```scale1``` to compute a scaling factor that matches the definition of scaling factor of TensorFlow Lite [2][3]. In fact, one might imagine that the scaling factor provided by the ```scale``` attribute of ```quantized_bits()``` is the same as the TensorFlow one: unfortunately it is not, as you can see from [quantizers.py#L608](https://github.com/google/qkeras/blob/b91d8815b31f05ddf9c7b6d62381df9be72a570a/qkeras/quantizers.py#L608). The correct scaling factor is ```scale = scale1 * m_i``` and has to be computed manually.\n",
    "\n",
    "Finally, the following calculations show the <b>quantization of the weights</b>, which is a <b>per-channel</b>  approach, i.e. weights have a number of scaling factors and zero points equal to the number of output channels, while <b>activations are quantized in a per-layer fashion</b> (one scaling factor and one zero point for each feature map tensor). The difference is the use of ```scale_axis=0```in ```quantized_bits()``` for ```QActivation()```. The reason why per-channel quantization of activations is not implemented in QKeras, as well as in TensorFlow Lite, is because \"<i>per-channel quantization of activations is much harder to implement because we cannot factor the scale factor out of the summation and would, therefore, require rescaling the accumulator for each input channel</i>\" [4]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_calibration_data(model, x_test, calibration_samples, csv_file_path_w, csv_file_path_a):\n",
    "\n",
    "    \"\"\"Return two dictionaries: one for weights and biases, and one for activations\n",
    "       1) weight and bias: scale and zero-point are known and fixed (zero-point = 0)\n",
    "       2) activations: scale and bias vary with the input -->\n",
    "                       --> need calibration set to get maximum absolute values of alpha and beta\n",
    "    \"\"\"\n",
    "\n",
    "    zeropoint_of_list = []\n",
    "    ready1 = 0\n",
    "\n",
    "    layers_list = [layer for layer in model.layers]\n",
    "\n",
    "    # TODO\n",
    "\n",
    "    # Define the weights and biases dictionary\n",
    "    base_param_dict = {\n",
    "               \"w_scale\": 0,\n",
    "               \"b_scale\": 0,\n",
    "               \"subq1\": [],\n",
    "               \"wq\": [],\n",
    "               \"bq\": []\n",
    "    }\n",
    "    \n",
    "    w_layers = []\n",
    "    for layer in layers_list:\n",
    "        if layer.__class__.__name__ in [\"QConv2D\", \"QConv2DBatchnorm\", \n",
    "                                        \"QDepthwiseConv2D\", \"QDepthwiseConv2DBatchnorm\", \n",
    "                                        \"QDense\", \"QDenseBatchnorm\"]:\n",
    "            w_layers.append(layer.name)\n",
    "\n",
    "    # Deepcopy base dict otherwise it is always the same object\n",
    "    w_dict = {k: dc(base_param_dict) for k in w_layers}\n",
    "\n",
    "    # Define the activations dictionary\n",
    "    base_act_dict = {\n",
    "        \"alpha_of_max_abs\": [],\n",
    "        \"beta_of_max_abs\": [],\n",
    "        \"in_scale\": [],\n",
    "        \"in_zeropoint\":[]\n",
    "    }\n",
    "    \n",
    "    \n",
    "    a_layers = []\n",
    "    for layer in layers_list:\n",
    "        if layer.__class__.__name__ in [\"QActivation\"]:\n",
    "            a_layers.append(layer.name)\n",
    "    \n",
    "    a_dict = {k: dc(base_act_dict) for k in a_layers}   \n",
    "                       \n",
    "    \n",
    "    \n",
    "    # Extract maxium absolute values of alpha and beta of activations with calibration\n",
    "    for layer in layers_list:\n",
    "    \n",
    "        alpha_of_list = []\n",
    "        beta_of_list = []\n",
    "        \n",
    "        ##### FEATURES #####\n",
    "        if layer.__class__.__name__ in [\"QActivation\"]:\n",
    "                \n",
    "            for iter, x in enumerate(x_test[0:calibration_samples]):\n",
    "\n",
    "                data = x.reshape(1, x.shape[0], x.shape[1], x.shape[2])\n",
    "\n",
    "                pred_model = np.asarray(model.predict(data, batch_size=1, verbose=0), dtype=np.float64)\n",
    "\n",
    "                # axis 0 is for batch, 1 and 2 are for feature map, 3 is for channels\n",
    "                quantizer_of = layer.quantizer # it is quantized_bits_featuremap\n",
    "                \n",
    "                alpha_of = quantizer_of.alpha_f.numpy().flatten()\n",
    "                beta_of = quantizer_of.beta_f.numpy().flatten()\n",
    "                alpha_of_list.append(alpha_of)\n",
    "                beta_of_list.append(beta_of)\n",
    "            \n",
    "                print(f\"Layer {layer.name}, Calibration {iter+1}/{calibration_samples}\")\n",
    "            \n",
    "            alpha_of_max_abs = np.max(np.abs(alpha_of_list))\n",
    "            beta_of_max_abs = np.max(np.abs(beta_of_list))\n",
    "            \n",
    "            print(layer.name, alpha_of_max_abs, beta_of_max_abs)\n",
    "            \n",
    "            a_dict[layer.name][\"alpha_of_max_abs\"].append(alpha_of_max_abs)\n",
    "            a_dict[layer.name][\"beta_of_max_abs\"].append(beta_of_max_abs)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Extract weights, biases and activations\n",
    "    x = x_test[0]\n",
    "    data = x.reshape(1, x.shape[0], x.shape[1], x.shape[2])\n",
    "\n",
    "    pred_model = np.asarray(model.predict(data, batch_size=1, verbose=0), dtype=np.float64)\n",
    "\n",
    "    for iter, layer in enumerate(layers_list):\n",
    "        extractor = tf.keras.Model( inputs=model.inputs,\n",
    "                                   outputs=model.get_layer(layer.name).output)\n",
    "        of = extractor(data).numpy()\n",
    "        \n",
    "        ##### WEIGHTS AND BIASES #####\n",
    "        if layer.__class__.__name__ in [\"QConv2D\", \"QConv2DBatchnorm\", \n",
    "                                        \"QDepthwiseConv2D\", \"QDepthwiseConv2DBatchnorm\", \n",
    "                                        \"QDense\", \"QDenseBatchnorm\"]:\n",
    "\n",
    "            ##### WEIGHTS #####\n",
    "            if layer.__class__.__name__ in [\"QConv2D\", \"QDepthwiseConv2D\", \"QDense\"]:\n",
    "                parameters = layer.weights\n",
    "            else:\n",
    "                parameters = layer.get_folded_weights() # folded weights not quantized\n",
    "\n",
    "            w = parameters[0].numpy()\n",
    "            quantizer_w = layer.get_quantizers()[0] # it is quantized_bits\n",
    "            alphaq_w = quantizer_w.alphaq\n",
    "            betaq_w = quantizer_w.betaq\n",
    "            scale1_w = quantizer_w.scale1.numpy().flatten()\n",
    "            m_i = quantizer_w.m_i.numpy().flatten()\n",
    "            scale_w = scale1_w * m_i # WEIGHT SCALE\n",
    "\n",
    "            if scale_w != 0:\n",
    "                tmp = np.divide(w, scale_w, dtype=np.float64)\n",
    "                tmp[np.isnan(tmp)] = 0\n",
    "                tmp[np.isinf(tmp)] = 0\n",
    "                wq = np.clip(np.trunc(tmp + np.sign(tmp)*0.5), alphaq_w, betaq_w)\n",
    "            else:\n",
    "                wq = np.zeros(w.size)\n",
    "\n",
    "            # \"subq1\" (part 2)\n",
    "            if layer.__class__.__name__ in [\"QConv2D\", \"QConv2DBatchnorm\"]:\n",
    "                sum_of_weights = wq.sum(axis=(0, 1, 2))\n",
    "            elif layer.__class__.__name__ in [\"QDense\", \"QDenseBatchnorm\"]:\n",
    "                sum_of_weights = wq.sum(axis=0)\n",
    "            if layer.__class__.__name__ in [\"QDepthwiseConv2D\", \"QDepthwiseConv2DBatchnorm\"]:\n",
    "                sum_of_weights = wq.sum(axis=(0, 1))\n",
    "\n",
    "            if ready1 == 1:\n",
    "                subq1 = (zeropoint_of_list[-1] * sum_of_weights).flatten()\n",
    "                ready1 = 0\n",
    "                w_dict[layer.name][\"subq1\"] = subq1\n",
    "\n",
    "\n",
    "            ##### BIASES ######\n",
    "            quantizer_b = layer.get_quantizers()[1] # it is quantized_bits\n",
    "            b = parameters[1].numpy()\n",
    "            alphaq_b = quantizer_b.alphaq\n",
    "            betaq_b = quantizer_b.betaq\n",
    "            scale1_b = quantizer_b.scale1.numpy().flatten()\n",
    "            m_i = quantizer_b.m_i.numpy().flatten()\n",
    "            scale_b = scale1_b * m_i # BIAS SCALE\n",
    "\n",
    "\n",
    "            if scale_b != 0:\n",
    "                tmp = np.divide(b, scale_b, dtype=np.float64)\n",
    "                tmp[np.isnan(tmp)] = 0\n",
    "                tmp[np.isinf(tmp)] = 0\n",
    "                bq = np.clip(np.trunc(tmp + np.sign(tmp)*0.5), alphaq_b, betaq_b)\n",
    "            else:\n",
    "                bq = np.zeros(b.size)\n",
    "\n",
    "            w_dict[layer.name]['w_scale'] = scale_w\n",
    "            w_dict[layer.name][\"b_scale\"] = scale_b\n",
    "            w_dict[layer.name][\"wq\"] = wq\n",
    "            w_dict[layer.name][\"bq\"] = bq\n",
    "\n",
    "            \n",
    "        ##### FEATURES #####\n",
    "        elif layer.__class__.__name__ in [\"QActivation\"]:\n",
    "\n",
    "            quantizer_of = layer.quantizer # it is quantized_bits_featuremap\n",
    "            alphaq_of = quantizer_of.alphaq\n",
    "            betaq_of = quantizer_of.betaq\n",
    "\n",
    "            alpha_of_max_abs = a_dict[layer.name][\"alpha_of_max_abs\"][0]\n",
    "            beta_of_max_abs = a_dict[layer.name][\"beta_of_max_abs\"][0]\n",
    "                        \n",
    "            scale_of = np.asarray([(beta_of_max_abs - alpha_of_max_abs) / \\\n",
    "                                   (betaq_of - alphaq_of)], dtype=np.float64)\n",
    "            scale_of[np.isnan(scale_of)] = 0\n",
    "            scale_of[np.isinf(scale_of)] = 0\n",
    "            scale_of = scale_of[0] # ACTIVATION SCALE\n",
    "\n",
    "            z_of = np.asarray([np.around(((beta_of_max_abs*alphaq_of - alpha_of_max_abs*betaq_of)/ \\\n",
    "                                          (beta_of_max_abs - alpha_of_max_abs)), 0)], dtype=np.float64)\n",
    "            z_of[np.isnan(z_of)] = 0\n",
    "            z_of[np.isinf(z_of)] = 0\n",
    "            z_of = z_of[0] # ACTIVATION ZERO-POINT\n",
    "            zeropoint_of_list.append(z_of)\n",
    "            \n",
    "            ready1 = 1 # \"subq1\" (part 1)\n",
    "\n",
    "            a_dict[layer.name][\"in_scale\"].append(scale_of)\n",
    "            a_dict[layer.name][\"in_zeropoint\"].append(z_of)\n",
    "\n",
    "        print(f\"LAYER: {iter+1}/{len(layers_list)}\")\n",
    "        \n",
    "        \n",
    " \n",
    "    # Index will be determined by the first layer of nested dictionaries (layers)\n",
    "    df_w = pd.DataFrame.from_dict(w_dict, orient=\"index\")\n",
    "    df_a = pd.DataFrame.from_dict(a_dict, orient=\"index\")\n",
    "    \n",
    "    df_w.to_csv(csv_file_path_w)\n",
    "    df_a.to_csv(csv_file_path_a)\n",
    "    \n",
    "    return (df_w, df_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer act_0, Calibration 1/2\n",
      "Layer act_0, Calibration 2/2\n",
      "act_0 0.3100356161594391 0.9853548407554626\n",
      "Layer act_1, Calibration 1/2\n",
      "Layer act_1, Calibration 2/2\n",
      "act_1 0.0 0.6093715421191592\n",
      "Layer act_2, Calibration 1/2\n",
      "Layer act_2, Calibration 2/2\n",
      "act_2 0.0 0.4016574329811613\n",
      "Layer act_3, Calibration 1/2\n",
      "Layer act_3, Calibration 2/2\n",
      "act_3 0.2778562754214806 0.13082906623615892\n",
      "LAYER: 1/13\n",
      "act_0 0.3100356161594391 0.9853548407554626\n",
      "LAYER: 2/13\n",
      "LAYER: 3/13\n",
      "LAYER: 4/13\n",
      "act_1 0.0 0.6093715421191592\n",
      "LAYER: 5/13\n",
      "LAYER: 6/13\n",
      "LAYER: 7/13\n",
      "LAYER: 8/13\n",
      "act_2 0.0 0.4016574329811613\n",
      "LAYER: 9/13\n",
      "LAYER: 10/13\n",
      "LAYER: 11/13\n",
      "act_3 0.2778562754214806 0.13082906623615892\n",
      "LAYER: 12/13\n",
      "LAYER: 13/13\n",
      "folder exists\n",
      "Extraction complete\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w_scale</th>\n",
       "      <th>b_scale</th>\n",
       "      <th>subq1</th>\n",
       "      <th>wq</th>\n",
       "      <th>bq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>conv2d_0</th>\n",
       "      <td>[1.605048697272615e-05, 2.4499327696476017e-05]</td>\n",
       "      <td>[-3.3643002406643334e-11]</td>\n",
       "      <td>[7345441551.0, 2692685373.0]</td>\n",
       "      <td>[[[[ -7436. -32767.]], [[-27414.   2209.]], [[...</td>\n",
       "      <td>[914530817.0, -1073741823.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conv2d_1</th>\n",
       "      <td>[3.2917795977453265e-05, 2.5136744723604712e-0...</td>\n",
       "      <td>[-9.248198461677534e-11]</td>\n",
       "      <td>[-529023215.0, 1038189628.0, -117371394.0]</td>\n",
       "      <td>[[[[-2417. 24149. 16138.], [ 10385.   5108. -2...</td>\n",
       "      <td>[322975889.0, -1073741823.0, 469599030.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dense</th>\n",
       "      <td>[2.0115614274990533e-05]</td>\n",
       "      <td>[-7.587447050980372e-11]</td>\n",
       "      <td>[1926306396.0, -1158444518.0, 1019741807.0, 10...</td>\n",
       "      <td>[[16320.0, -6222.0, -1639.0, -15814.0, 24913.0...</td>\n",
       "      <td>[158956117.0, 1004136881.0, -765871401.0, -107...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    w_scale  \\\n",
       "conv2d_0    [1.605048697272615e-05, 2.4499327696476017e-05]   \n",
       "conv2d_1  [3.2917795977453265e-05, 2.5136744723604712e-0...   \n",
       "dense                              [2.0115614274990533e-05]   \n",
       "\n",
       "                            b_scale  \\\n",
       "conv2d_0  [-3.3643002406643334e-11]   \n",
       "conv2d_1   [-9.248198461677534e-11]   \n",
       "dense      [-7.587447050980372e-11]   \n",
       "\n",
       "                                                      subq1  \\\n",
       "conv2d_0                       [7345441551.0, 2692685373.0]   \n",
       "conv2d_1         [-529023215.0, 1038189628.0, -117371394.0]   \n",
       "dense     [1926306396.0, -1158444518.0, 1019741807.0, 10...   \n",
       "\n",
       "                                                         wq  \\\n",
       "conv2d_0  [[[[ -7436. -32767.]], [[-27414.   2209.]], [[...   \n",
       "conv2d_1  [[[[-2417. 24149. 16138.], [ 10385.   5108. -2...   \n",
       "dense     [[16320.0, -6222.0, -1639.0, -15814.0, 24913.0...   \n",
       "\n",
       "                                                         bq  \n",
       "conv2d_0                       [914530817.0, -1073741823.0]  \n",
       "conv2d_1          [322975889.0, -1073741823.0, 469599030.0]  \n",
       "dense     [158956117.0, 1004136881.0, -765871401.0, -107...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha_of_max_abs</th>\n",
       "      <th>beta_of_max_abs</th>\n",
       "      <th>in_scale</th>\n",
       "      <th>in_zeropoint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>act_0</th>\n",
       "      <td>[0.3100356161594391]</td>\n",
       "      <td>[0.9853548407554626]</td>\n",
       "      <td>[1.030486807757841e-05]</td>\n",
       "      <td>[-62853.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act_1</th>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[0.6093715421191592]</td>\n",
       "      <td>[9.298555591283292e-06]</td>\n",
       "      <td>[-32767.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act_2</th>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[0.4016574329811613]</td>\n",
       "      <td>[6.128993087270139e-06]</td>\n",
       "      <td>[-32767.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act_3</th>\n",
       "      <td>[0.2778562754214806]</td>\n",
       "      <td>[0.13082906623615892]</td>\n",
       "      <td>[-2.243525638375831e-06]</td>\n",
       "      <td>[91081.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           alpha_of_max_abs        beta_of_max_abs                  in_scale  \\\n",
       "act_0  [0.3100356161594391]   [0.9853548407554626]   [1.030486807757841e-05]   \n",
       "act_1                 [0.0]   [0.6093715421191592]   [9.298555591283292e-06]   \n",
       "act_2                 [0.0]   [0.4016574329811613]   [6.128993087270139e-06]   \n",
       "act_3  [0.2778562754214806]  [0.13082906623615892]  [-2.243525638375831e-06]   \n",
       "\n",
       "      in_zeropoint  \n",
       "act_0   [-62853.0]  \n",
       "act_1   [-32767.0]  \n",
       "act_2   [-32767.0]  \n",
       "act_3    [91081.0]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# User settings\n",
    "\n",
    "calibration_samples = 2\n",
    "\n",
    "#------------------------------------------\n",
    "\n",
    "(df_w, df_a) = extract_calibration_data(qmodel, x_test, calibration_samples,\n",
    "                                        output_folder+\"/extracted_weights.csv\",\n",
    "                                        output_folder+\"/extracted_activations.csv\")\n",
    "\n",
    "output_folder = \"./calibration_results\"\n",
    "\n",
    "try:\n",
    "    os.mkdir(output_folder)\n",
    "except:\n",
    "    print(\"folder exists\")\n",
    "\n",
    "print(\"Extraction complete\")\n",
    "\n",
    "display(df_w)\n",
    "display(df_a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a class=\"anchor\" id=\"ch4\"></a>\n",
    "# 4) Quantized network design for AutoQKeras\n",
    "\n",
    "Go to [Top](#top).\n",
    "\n",
    "Go to others: [Ch. 0](#ch0), [Ch. 1](#ch1), [Ch. 2](#ch2), [Ch. 3](#ch3), [Ch. 4](#ch4).\n",
    "\n",
    "To perform an hyperparameter search on a Keras model with AutoQKeras, we need to pass the Keras model to the first argument of the AutoQKeras class to create an AutoQKeras object. The input Keras model is automatically converted to a QKeras model during the building process by the ```quantize_model()``` method of AutoQKHyperModel class (see [autoqkeras_internal.py#L570](https://github.com/google/qkeras/blob/1ab354276a041b45cd72c300e89a7c51ec99fa35/qkeras/autoqkeras/autoqkeras_internal.py#L570)). \n",
    "\n",
    "The idea is to exploit this automatic convertion to realize a QKeras model according to the methodology previously described in this notebook ([Ch. 1](#ch1)) with as minimum changes as possible to the original Keras model definition, as explained here:\n",
    "\n",
    "1) Every 2DConv, DWConv and FC layer has to be anticipated by an ```Activation``` layer with whatever activation function (we don't care about the type of activation because it will be replaced by AutoQKeras during the search with the ```activation``` values defined in the search space ```quantization_config```). In this example we are going to use \"sigmoid\", but any other type would be fine;\n",
    "\n",
    "2) The last 2DConv, DWConv or FC layer of the network has also to be followed by an ```Activation``` layer, as written in the previous point;\n",
    "\n",
    "3) Every ```BatchNormalization``` layer that follows a 2DConv or DWConv layer has to be fused with the convolution. We can use the flag ```enable_bn_folding=True``` when instantiating the AutoQKeras object to automatically do the batch normalization fusion;\n",
    "\n",
    "4) Every activation layer associated to a convolutional or fully-connected layer, either declared as argument of the ```Activation``` layer (such as ```Activation(activation=\"relu\")```), or declared as argument of the ```Conv2D```, ```DepthwiseConv2D``` or ```Dense``` layer (such as ```Conv2D(activation=\"relu\")```), has to be written in the \"direct\" form, i.e. using a layer that has the same name of the activation (such as ```ReLU()```);\n",
    "\n",
    "5) The activations not associated to a convolutional or fully-connected layer, usually those placed as last layer of CNNs (such as softmax), has not to be changed;\n",
    "\n",
    "6) Any other layer, such as pooling or add layers, has not to be changed;\n",
    "\n",
    "7) After average pooling, since the average of integers is not necessarily an integer, a quantization step is required (it would be better to use the same quantizer used for its input because its output range does not significantly change). Moreover, the dynamic of the activations changes between input and output of pooling. So an ```Activation``` layer is required after an average pooling;\n",
    "\n",
    "8) For residual connections (\"add\" layers), do as the next cell shows.\n",
    "\n",
    "Things to know:\n",
    "- ```quantize_model()``` does not accept an input model with QKeras layers\n",
    "\n",
    "To run the next cells without issues, you should edit the file [autoqkeras/autoqkeras_internal.py](https://github.com/google/qkeras/blob/master/qkeras/autoqkeras/autoqkeras_internal.py) to expose the flag ```enable_bn_folding``` to the AutoQKeras interface (externally) and to connect it to the ```AutoQKHyperModel``` class and its ```model_quantize``` method (internally)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified Keras model for AutoQKeras\n",
    "model2 = tf.keras.models.Sequential([\n",
    "    \n",
    "    MaxPooling2D(pool_size=pool_size_list[0], name=\"pool_0\"),\n",
    "    Activation(\"sigmoid\", name=\"act_0\"), # fake relu\n",
    "    \n",
    "    # Esempio conv senza batchnorm\n",
    "    Conv2D(filters=filters_list[0], kernel_size=kernel_size_list[0], strides=strides_list[0], padding=pads_list[0], name=\"conv2d_0\"),\n",
    "          #activation=\"relu\"),\n",
    "    ReLU(name=\"relu_0\"), # real relu\n",
    "    Activation(\"sigmoid\", name=\"act_1\"), # fake relu\n",
    "    \n",
    "    # Esempio conv con batchnorm\n",
    "    Conv2D(filters_list[1], kernel_size_list[1], strides_list[1], pads_list[1], name=\"conv2d_1\"),\n",
    "    BatchNormalization(name=\"bn_1\"),\n",
    "    ReLU(name=\"relu_1\"), # real relu\n",
    "    Activation(\"sigmoid\", name=\"act_2\"), # fake relu\n",
    "    \n",
    "    Flatten(name=\"flatten\"),\n",
    "    \n",
    "    # Esempio dense senza batchnorm\n",
    "    Dense(units_list[0], name=\"dense\"),\n",
    "    Activation(\"sigmoid\", name=\"act_3\"), # fake relu\n",
    "  \n",
    "    Activation(\"softmax\", name=\"softmax\")\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.build((None,input_width,input_width,input_channels))\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(Adam(lr=0.001), loss=['categorical_crossentropy'], metrics=['accuracy'],\n",
    "               run_eagerly=True)\n",
    "\n",
    "if tf.config.list_physical_devices('GPU') == []:\n",
    "    print(\"No GPU available\")\n",
    "else:\n",
    "    print(\"GPU available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale_axis=0 does a per-layer quantization, i.e. one scaling factor for the entire layer\n",
    "# otherwise qkeras automatically does a per-channel quantization, i.e. one scaling facor for each channel in layer\n",
    "# we want a per-channel quantization for weigths/biases and a per-layer quantization for activations\n",
    "quantization_config = {\n",
    "        \"kernel\": {\n",
    "                \"quantized_bits(4,4,1,1,alpha='auto')\": 4,\n",
    "                \"quantized_bits(8,8,1,1,alpha='auto')\": 8,\n",
    "                \"quantized_bits(16,16,1,1,alpha='auto')\": 16,\n",
    "        },\n",
    "        \"bias\": {\n",
    "                \"quantized_bits(16,16,1,1,alpha='auto')\": 16,\n",
    "                \"quantized_bits(31,31,1,1,alpha='auto')\": 31,\n",
    "        },\n",
    "        \"activation\": {\n",
    "                \"quantized_bits(4,4,1,1,alpha='auto',scale_axis=0)\": 4,\n",
    "                \"quantized_bits(8,8,1,1,alpha='auto',scale_axis=0)\": 8,\n",
    "                \"quantized_bits(16,16,1,1,alpha='auto',scale_axis=0)\": 16\n",
    "        }\n",
    "}\n",
    "\n",
    "# w, b, a\n",
    "limit = {\n",
    "    \"Dense\": [16, 31, 16],\n",
    "    \"Conv2D\": [16, 31, 16],\n",
    "    \"DepthwiseConv2D\": [16, 31, 16],\n",
    "    \"Activation\": [16],\n",
    "    \"BatchNormalization\": []\n",
    "}\n",
    "\n",
    "goal = {\n",
    "    \"type\": \"energy\",\n",
    "    \"params\": {\n",
    "        \"delta_p\": 5.0,\n",
    "        \"delta_n\": 5.0,\n",
    "        \"rate\": 2.0,\n",
    "        \"stress\": 1.0,\n",
    "        \"process\": \"horowitz\",\n",
    "        \"parameters_on_memory\": [\"sram\", \"sram\"],\n",
    "        \"activations_on_memory\": [\"sram\", \"sram\"],\n",
    "        \"rd_wr_on_io\": [False, False],\n",
    "        \"min_sram_size\": [0, 0],\n",
    "        \"source_quantizers\": [\"int8\"],\n",
    "        \"reference_internal\": \"int8\",\n",
    "        \"reference_accumulator\": \"int16\"\n",
    "        }\n",
    "}\n",
    "\n",
    "run_config = {\n",
    "  \"output_dir\": \"./autoqkeras\",\n",
    "  \"goal\": goal,\n",
    "  \"quantization_config\": quantization_config,\n",
    "  \"learning_rate_optimizer\": False,\n",
    "  \"transfer_weights\": False,\n",
    "  \"mode\": \"random\",\n",
    "  \"seed\": 42,\n",
    "  \"limit\": limit,\n",
    "  \"tune_filters\": \"none\",\n",
    "  \"tune_filters_exceptions\": \"^dense\",\n",
    "  \"distribution_strategy\": tf.distribute.get_strategy(),\n",
    "  # first layer is input, layer two layers are softmax and flatten\n",
    "  \"layer_indexes\": range(1, len(model.layers) - 1),\n",
    "  \"max_trials\": 5\n",
    "}\n",
    "\n",
    "from qkeras.autoqkeras import *\n",
    "\n",
    "autoqk = AutoQKeras(model2, metrics=[\"acc\"], custom_objects={}, **run_config, enable_bn_folding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoqk.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=1024, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Go to next: [Ch. 5](#ch5).-->\n",
    "\n",
    "Go to others: [Ch. 0](#ch0), [Ch. 1](#ch1), [Ch. 2](#ch2), [Ch. 3](#ch3), [Ch. 4](#ch4).\n",
    "\n",
    "Go to [Top](#top)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
